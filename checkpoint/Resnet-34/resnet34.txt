conv1.weight torch.Size([64, 3, 3, 3])
bn1.weight torch.Size([64])
bn1.bias torch.Size([64])
layer1.0.conv1.weight torch.Size([64, 64, 3, 3])
layer1.0.bn1.weight torch.Size([64])
layer1.0.bn1.bias torch.Size([64])
layer1.0.conv2.weight torch.Size([64, 64, 3, 3])
layer1.0.bn2.weight torch.Size([64])
layer1.0.bn2.bias torch.Size([64])
layer1.1.conv1.weight torch.Size([64, 64, 3, 3])
layer1.1.bn1.weight torch.Size([64])
layer1.1.bn1.bias torch.Size([64])
layer1.1.conv2.weight torch.Size([64, 64, 3, 3])
layer1.1.bn2.weight torch.Size([64])
layer1.1.bn2.bias torch.Size([64])
layer1.2.conv1.weight torch.Size([64, 64, 3, 3])
layer1.2.bn1.weight torch.Size([64])
layer1.2.bn1.bias torch.Size([64])
layer1.2.conv2.weight torch.Size([64, 64, 3, 3])
layer1.2.bn2.weight torch.Size([64])
layer1.2.bn2.bias torch.Size([64])
layer2.0.conv1.weight torch.Size([128, 64, 3, 3])
layer2.0.bn1.weight torch.Size([128])
layer2.0.bn1.bias torch.Size([128])
layer2.0.conv2.weight torch.Size([128, 128, 3, 3])
layer2.0.bn2.weight torch.Size([128])
layer2.0.bn2.bias torch.Size([128])
layer2.0.shortcut.0.weight torch.Size([128, 64, 1, 1])
layer2.0.shortcut.1.weight torch.Size([128])
layer2.0.shortcut.1.bias torch.Size([128])
layer2.1.conv1.weight torch.Size([128, 128, 3, 3])
layer2.1.bn1.weight torch.Size([128])
layer2.1.bn1.bias torch.Size([128])
layer2.1.conv2.weight torch.Size([128, 128, 3, 3])
layer2.1.bn2.weight torch.Size([128])
layer2.1.bn2.bias torch.Size([128])
layer2.2.conv1.weight torch.Size([128, 128, 3, 3])
layer2.2.bn1.weight torch.Size([128])
layer2.2.bn1.bias torch.Size([128])
layer2.2.conv2.weight torch.Size([128, 128, 3, 3])
layer2.2.bn2.weight torch.Size([128])
layer2.2.bn2.bias torch.Size([128])
layer2.3.conv1.weight torch.Size([128, 128, 3, 3])
layer2.3.bn1.weight torch.Size([128])
layer2.3.bn1.bias torch.Size([128])
layer2.3.conv2.weight torch.Size([128, 128, 3, 3])
layer2.3.bn2.weight torch.Size([128])
layer2.3.bn2.bias torch.Size([128])
layer3.0.conv1.weight torch.Size([256, 128, 3, 3])
layer3.0.bn1.weight torch.Size([256])
layer3.0.bn1.bias torch.Size([256])
layer3.0.conv2.weight torch.Size([256, 256, 3, 3])
layer3.0.bn2.weight torch.Size([256])
layer3.0.bn2.bias torch.Size([256])
layer3.0.shortcut.0.weight torch.Size([256, 128, 1, 1])
layer3.0.shortcut.1.weight torch.Size([256])
layer3.0.shortcut.1.bias torch.Size([256])
layer3.1.conv1.weight torch.Size([256, 256, 3, 3])
layer3.1.bn1.weight torch.Size([256])
layer3.1.bn1.bias torch.Size([256])
layer3.1.conv2.weight torch.Size([256, 256, 3, 3])
layer3.1.bn2.weight torch.Size([256])
layer3.1.bn2.bias torch.Size([256])
layer3.2.conv1.weight torch.Size([256, 256, 3, 3])
layer3.2.bn1.weight torch.Size([256])
layer3.2.bn1.bias torch.Size([256])
layer3.2.conv2.weight torch.Size([256, 256, 3, 3])
layer3.2.bn2.weight torch.Size([256])
layer3.2.bn2.bias torch.Size([256])
layer3.3.conv1.weight torch.Size([256, 256, 3, 3])
layer3.3.bn1.weight torch.Size([256])
layer3.3.bn1.bias torch.Size([256])
layer3.3.conv2.weight torch.Size([256, 256, 3, 3])
layer3.3.bn2.weight torch.Size([256])
layer3.3.bn2.bias torch.Size([256])
layer3.4.conv1.weight torch.Size([256, 256, 3, 3])
layer3.4.bn1.weight torch.Size([256])
layer3.4.bn1.bias torch.Size([256])
layer3.4.conv2.weight torch.Size([256, 256, 3, 3])
layer3.4.bn2.weight torch.Size([256])
layer3.4.bn2.bias torch.Size([256])
layer3.5.conv1.weight torch.Size([256, 256, 3, 3])
layer3.5.bn1.weight torch.Size([256])
layer3.5.bn1.bias torch.Size([256])
layer3.5.conv2.weight torch.Size([256, 256, 3, 3])
layer3.5.bn2.weight torch.Size([256])
layer3.5.bn2.bias torch.Size([256])
layer4.0.conv1.weight torch.Size([512, 256, 3, 3])
layer4.0.bn1.weight torch.Size([512])
layer4.0.bn1.bias torch.Size([512])
layer4.0.conv2.weight torch.Size([512, 512, 3, 3])
layer4.0.bn2.weight torch.Size([512])
layer4.0.bn2.bias torch.Size([512])
layer4.0.shortcut.0.weight torch.Size([512, 256, 1, 1])
layer4.0.shortcut.1.weight torch.Size([512])
layer4.0.shortcut.1.bias torch.Size([512])
layer4.1.conv1.weight torch.Size([512, 512, 3, 3])
layer4.1.bn1.weight torch.Size([512])
layer4.1.bn1.bias torch.Size([512])
layer4.1.conv2.weight torch.Size([512, 512, 3, 3])
layer4.1.bn2.weight torch.Size([512])
layer4.1.bn2.bias torch.Size([512])
layer4.2.conv1.weight torch.Size([512, 512, 3, 3])
layer4.2.bn1.weight torch.Size([512])
layer4.2.bn1.bias torch.Size([512])
layer4.2.conv2.weight torch.Size([512, 512, 3, 3])
layer4.2.bn2.weight torch.Size([512])
layer4.2.bn2.bias torch.Size([512])
fc.weight torch.Size([10, 512])
fc.bias torch.Size([10])
accuracy: 95.69000244140625                                                                      
macs: 1160427008
sparsity: 0.0
model size:81.18MB
Precision: 0.9569, Recall: 0.9569, F1: 0.9569
[[966   1   8   3   2   0   1   0  15   4]
 [  2 979   0   1   0   0   0   0   3  15]
 [  9   0 939  15  10  10   8   6   3   0]
 [  4   1  10 908   8  47  11   4   4   3]
 [  2   0   6  12 962   6   3   8   0   1]
 [  2   0   7  45  10 927   3   5   0   1]
 [  6   0   7  14   1   0 969   1   0   2]
 [  4   0   2   7   8   6   0 972   0   1]
 [ 11   4   2   0   0   0   0   0 973  10]
 [  3  14   2   1   0   0   0   1   5 974]]
CPU latency: 0.026547443866729737
GPU latency: 0.0031075978279113767

FGP:
conv1.weight torch.Size([64, 3, 3, 3])
bn1.weight torch.Size([64])
bn1.bias torch.Size([64])
layer1.0.conv1.weight torch.Size([64, 64, 3, 3])
layer1.0.bn1.weight torch.Size([64])
layer1.0.bn1.bias torch.Size([64])
layer1.0.conv2.weight torch.Size([64, 64, 3, 3])
layer1.0.bn2.weight torch.Size([64])
layer1.0.bn2.bias torch.Size([64])
layer1.1.conv1.weight torch.Size([64, 64, 3, 3])
layer1.1.bn1.weight torch.Size([64])
layer1.1.bn1.bias torch.Size([64])
layer1.1.conv2.weight torch.Size([64, 64, 3, 3])
layer1.1.bn2.weight torch.Size([64])
layer1.1.bn2.bias torch.Size([64])
layer1.2.conv1.weight torch.Size([64, 64, 3, 3])
layer1.2.bn1.weight torch.Size([64])
layer1.2.bn1.bias torch.Size([64])
layer1.2.conv2.weight torch.Size([64, 64, 3, 3])
layer1.2.bn2.weight torch.Size([64])
layer1.2.bn2.bias torch.Size([64])
layer2.0.conv1.weight torch.Size([128, 64, 3, 3])
layer2.0.bn1.weight torch.Size([128])
layer2.0.bn1.bias torch.Size([128])
layer2.0.conv2.weight torch.Size([128, 128, 3, 3])
layer2.0.bn2.weight torch.Size([128])
layer2.0.bn2.bias torch.Size([128])
layer2.0.shortcut.0.weight torch.Size([128, 64, 1, 1])
layer2.0.shortcut.1.weight torch.Size([128])
layer2.0.shortcut.1.bias torch.Size([128])
layer2.1.conv1.weight torch.Size([128, 128, 3, 3])
layer2.1.bn1.weight torch.Size([128])
layer2.1.bn1.bias torch.Size([128])
layer2.1.conv2.weight torch.Size([128, 128, 3, 3])
layer2.1.bn2.weight torch.Size([128])
layer2.1.bn2.bias torch.Size([128])
layer2.2.conv1.weight torch.Size([128, 128, 3, 3])
layer2.2.bn1.weight torch.Size([128])
layer2.2.bn1.bias torch.Size([128])
layer2.2.conv2.weight torch.Size([128, 128, 3, 3])
layer2.2.bn2.weight torch.Size([128])
layer2.2.bn2.bias torch.Size([128])
layer2.3.conv1.weight torch.Size([128, 128, 3, 3])
layer2.3.bn1.weight torch.Size([128])
layer2.3.bn1.bias torch.Size([128])
layer2.3.conv2.weight torch.Size([128, 128, 3, 3])
layer2.3.bn2.weight torch.Size([128])
layer2.3.bn2.bias torch.Size([128])
layer3.0.conv1.weight torch.Size([256, 128, 3, 3])
layer3.0.bn1.weight torch.Size([256])
layer3.0.bn1.bias torch.Size([256])
layer3.0.conv2.weight torch.Size([256, 256, 3, 3])
layer3.0.bn2.weight torch.Size([256])
layer3.0.bn2.bias torch.Size([256])
layer3.0.shortcut.0.weight torch.Size([256, 128, 1, 1])
layer3.0.shortcut.1.weight torch.Size([256])
layer3.0.shortcut.1.bias torch.Size([256])
layer3.1.conv1.weight torch.Size([256, 256, 3, 3])
layer3.1.bn1.weight torch.Size([256])
layer3.1.bn1.bias torch.Size([256])
layer3.1.conv2.weight torch.Size([256, 256, 3, 3])
layer3.1.bn2.weight torch.Size([256])
layer3.1.bn2.bias torch.Size([256])
layer3.2.conv1.weight torch.Size([256, 256, 3, 3])
layer3.2.bn1.weight torch.Size([256])
layer3.2.bn1.bias torch.Size([256])
layer3.2.conv2.weight torch.Size([256, 256, 3, 3])
layer3.2.bn2.weight torch.Size([256])
layer3.2.bn2.bias torch.Size([256])
layer3.3.conv1.weight torch.Size([256, 256, 3, 3])
layer3.3.bn1.weight torch.Size([256])
layer3.3.bn1.bias torch.Size([256])
layer3.3.conv2.weight torch.Size([256, 256, 3, 3])
layer3.3.bn2.weight torch.Size([256])
layer3.3.bn2.bias torch.Size([256])
layer3.4.conv1.weight torch.Size([256, 256, 3, 3])
layer3.4.bn1.weight torch.Size([256])
layer3.4.bn1.bias torch.Size([256])
layer3.4.conv2.weight torch.Size([256, 256, 3, 3])
layer3.4.bn2.weight torch.Size([256])
layer3.4.bn2.bias torch.Size([256])
layer3.5.conv1.weight torch.Size([256, 256, 3, 3])
layer3.5.bn1.weight torch.Size([256])
layer3.5.bn1.bias torch.Size([256])
layer3.5.conv2.weight torch.Size([256, 256, 3, 3])
layer3.5.bn2.weight torch.Size([256])
layer3.5.bn2.bias torch.Size([256])
layer4.0.conv1.weight torch.Size([512, 256, 3, 3])
layer4.0.bn1.weight torch.Size([512])
layer4.0.bn1.bias torch.Size([512])
layer4.0.conv2.weight torch.Size([512, 512, 3, 3])
layer4.0.bn2.weight torch.Size([512])
layer4.0.bn2.bias torch.Size([512])
layer4.0.shortcut.0.weight torch.Size([512, 256, 1, 1])
layer4.0.shortcut.1.weight torch.Size([512])
layer4.0.shortcut.1.bias torch.Size([512])
layer4.1.conv1.weight torch.Size([512, 512, 3, 3])
layer4.1.bn1.weight torch.Size([512])
layer4.1.bn1.bias torch.Size([512])
layer4.1.conv2.weight torch.Size([512, 512, 3, 3])
layer4.1.bn2.weight torch.Size([512])
layer4.1.bn2.bias torch.Size([512])
layer4.2.conv1.weight torch.Size([512, 512, 3, 3])
layer4.2.bn1.weight torch.Size([512])
layer4.2.bn1.bias torch.Size([512])
layer4.2.conv2.weight torch.Size([512, 512, 3, 3])
layer4.2.bn2.weight torch.Size([512])
layer4.2.bn2.bias torch.Size([512])
fc.weight torch.Size([10, 512])
fc.bias torch.Size([10])
accuracy: 95.0999984741211                                                                                                                                             
macs: 1160427008
sparsity: 0.8956148263786854
model size:8.47MB
Precision: 0.9511, Recall: 0.9510, F1: 0.9510
[[958   2   9   2   1   1   0   1  22   4]
 [  1 984   0   0   0   0   0   0   3  12]
 [ 16   0 929  14  11  12  10   4   4   0]
 [  6   0  13 892   8  57   8   8   5   3]
 [  5   0   6  11 956  11   4   5   1   1]
 [  4   1   2  41  13 929   3   6   0   1]
 [  3   0   9  16   2   2 965   1   1   1]
 [  3   0   2  10  12   9   0 964   0   0]
 [ 15   3   2   2   0   0   0   0 971   7]
 [  5  17   2   1   0   1   0   1  11 962]]
CPU latency: 0.02416717290878296
GPU latency: 0.003127875328063965

CP:
conv1.weight torch.Size([13, 3, 3, 3])
bn1.weight torch.Size([13])
bn1.bias torch.Size([13])
layer1.0.conv1.weight torch.Size([58, 13, 3, 3])
layer1.0.bn1.weight torch.Size([58])
layer1.0.bn1.bias torch.Size([58])
layer1.0.conv2.weight torch.Size([58, 58, 3, 3])
layer1.0.bn2.weight torch.Size([58])
layer1.0.bn2.bias torch.Size([58])
layer1.1.conv1.weight torch.Size([58, 58, 3, 3])
layer1.1.bn1.weight torch.Size([58])
layer1.1.bn1.bias torch.Size([58])
layer1.1.conv2.weight torch.Size([58, 58, 3, 3])
layer1.1.bn2.weight torch.Size([58])
layer1.1.bn2.bias torch.Size([58])
layer1.2.conv1.weight torch.Size([58, 58, 3, 3])
layer1.2.bn1.weight torch.Size([58])
layer1.2.bn1.bias torch.Size([58])
layer1.2.conv2.weight torch.Size([58, 58, 3, 3])
layer1.2.bn2.weight torch.Size([58])
layer1.2.bn2.bias torch.Size([58])
layer2.0.conv1.weight torch.Size([115, 58, 3, 3])
layer2.0.bn1.weight torch.Size([115])
layer2.0.bn1.bias torch.Size([115])
layer2.0.conv2.weight torch.Size([115, 115, 3, 3])
layer2.0.bn2.weight torch.Size([115])
layer2.0.bn2.bias torch.Size([115])
layer2.0.shortcut.0.weight torch.Size([115, 58, 1, 1])
layer2.0.shortcut.1.weight torch.Size([115])
layer2.0.shortcut.1.bias torch.Size([115])
layer2.1.conv1.weight torch.Size([102, 115, 3, 3])
layer2.1.bn1.weight torch.Size([102])
layer2.1.bn1.bias torch.Size([102])
layer2.1.conv2.weight torch.Size([102, 102, 3, 3])
layer2.1.bn2.weight torch.Size([102])
layer2.1.bn2.bias torch.Size([102])
layer2.2.conv1.weight torch.Size([102, 102, 3, 3])
layer2.2.bn1.weight torch.Size([102])
layer2.2.bn1.bias torch.Size([102])
layer2.2.conv2.weight torch.Size([102, 102, 3, 3])
layer2.2.bn2.weight torch.Size([102])
layer2.2.bn2.bias torch.Size([102])
layer2.3.conv1.weight torch.Size([102, 102, 3, 3])
layer2.3.bn1.weight torch.Size([102])
layer2.3.bn1.bias torch.Size([102])
layer2.3.conv2.weight torch.Size([102, 102, 3, 3])
layer2.3.bn2.weight torch.Size([102])
layer2.3.bn2.bias torch.Size([102])
layer3.0.conv1.weight torch.Size([205, 102, 3, 3])
layer3.0.bn1.weight torch.Size([205])
layer3.0.bn1.bias torch.Size([205])
layer3.0.conv2.weight torch.Size([205, 205, 3, 3])
layer3.0.bn2.weight torch.Size([205])
layer3.0.bn2.bias torch.Size([205])
layer3.0.shortcut.0.weight torch.Size([205, 102, 1, 1])
layer3.0.shortcut.1.weight torch.Size([205])
layer3.0.shortcut.1.bias torch.Size([205])
layer3.1.conv1.weight torch.Size([179, 205, 3, 3])
layer3.1.bn1.weight torch.Size([179])
layer3.1.bn1.bias torch.Size([179])
layer3.1.conv2.weight torch.Size([179, 179, 3, 3])
layer3.1.bn2.weight torch.Size([179])
layer3.1.bn2.bias torch.Size([179])
layer3.2.conv1.weight torch.Size([179, 179, 3, 3])
layer3.2.bn1.weight torch.Size([179])
layer3.2.bn1.bias torch.Size([179])
layer3.2.conv2.weight torch.Size([179, 179, 3, 3])
layer3.2.bn2.weight torch.Size([179])
layer3.2.bn2.bias torch.Size([179])
layer3.3.conv1.weight torch.Size([179, 179, 3, 3])
layer3.3.bn1.weight torch.Size([179])
layer3.3.bn1.bias torch.Size([179])
layer3.3.conv2.weight torch.Size([179, 179, 3, 3])
layer3.3.bn2.weight torch.Size([179])
layer3.3.bn2.bias torch.Size([179])
layer3.4.conv1.weight torch.Size([179, 179, 3, 3])
layer3.4.bn1.weight torch.Size([179])
layer3.4.bn1.bias torch.Size([179])
layer3.4.conv2.weight torch.Size([179, 179, 3, 3])
layer3.4.bn2.weight torch.Size([179])
layer3.4.bn2.bias torch.Size([179])
layer3.5.conv1.weight torch.Size([179, 179, 3, 3])
layer3.5.bn1.weight torch.Size([179])
layer3.5.bn1.bias torch.Size([179])
layer3.5.conv2.weight torch.Size([179, 179, 3, 3])
layer3.5.bn2.weight torch.Size([179])
layer3.5.bn2.bias torch.Size([179])
layer4.0.conv1.weight torch.Size([205, 179, 3, 3])
layer4.0.bn1.weight torch.Size([205])
layer4.0.bn1.bias torch.Size([205])
layer4.0.conv2.weight torch.Size([205, 205, 3, 3])
layer4.0.bn2.weight torch.Size([205])
layer4.0.bn2.bias torch.Size([205])
layer4.0.shortcut.0.weight torch.Size([205, 179, 1, 1])
layer4.0.shortcut.1.weight torch.Size([205])
layer4.0.shortcut.1.bias torch.Size([205])
layer4.1.conv1.weight torch.Size([102, 205, 3, 3])
layer4.1.bn1.weight torch.Size([102])
layer4.1.bn1.bias torch.Size([102])
layer4.1.conv2.weight torch.Size([102, 102, 3, 3])
layer4.1.bn2.weight torch.Size([102])
layer4.1.bn2.bias torch.Size([102])
layer4.2.conv1.weight torch.Size([51, 102, 3, 3])
layer4.2.bn1.weight torch.Size([51])
layer4.2.bn1.bias torch.Size([51])
layer4.2.conv2.weight torch.Size([51, 51, 3, 3])
layer4.2.bn2.weight torch.Size([51])
layer4.2.bn2.bias torch.Size([51])
fc.weight torch.Size([10, 51])
fc.bias torch.Size([10])
accuracy: 94.44999694824219                                                                                                                                            
/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: "aten::zeros_like". Skipped.
  warnings.warn('No handlers found: "{}". Skipped.'.format(
/home/zeus/miniconda3/envs/cloudspace/lib/python3.12/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: "aten::copy_". Skipped.
  warnings.warn('No handlers found: "{}". Skipped.'.format(
macs: 599912193
sparsity: 0.0
model size:21.13MB
Precision: 0.9448, Recall: 0.9445, F1: 0.9446
[[959   1  14   4   2   1   5   1   4   9]
 [  5 972   1   0   0   1   0   0   2  19]
 [  9   0 939  15  12  10  11   0   4   0]
 [  7   1  16 886  20  53   9   5   2   1]
 [  5   0   7  11 949   9   2  16   0   1]
 [  2   0  10  54  15 911   3   4   0   1]
 [  5   0  14  17   3   4 954   0   0   3]
 [  4   0   4   7  10  13   2 959   1   0]
 [ 23   6   6   4   0   0   1   1 945  14]
 [  4  19   1   3   0   1   0   0   1 971]]
CPU latency: 0.016636419296264648
GPU latency: 0.003669705390930176